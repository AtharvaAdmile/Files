
DL EXP 01




import pandas as pd

df = pd.read_csv("/content/cinema_hall_ticket_sales.csv")
print(df)

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split


# get the locations
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

# split the dataset
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 0 )


print(X_train)


----------------------------------------------------------------------------------------------


ðŸŽ¯ AIM
To load the MNIST dataset and split it into training, validation, and testing sets for model development.

ðŸ”¹ 1. Loading the Dataset
The MNIST dataset is a built-in dataset in TensorFlow/Keras containing 70,000 grayscale images of handwritten digits (0â€“9). It is loaded using the command:

python
Copy
Edit
(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
Here, X_train_full and y_train_full contain 60,000 training images and labels, while X_test contains 10,000 test samples.

ðŸ”¹ 2. Rescaling and Reshaping
The pixel values are normalized to the range [0, 1] by dividing by 255. The data is also reshaped to include a channel dimension (28, 28, 1) for compatibility with CNN models.

ðŸ”¹ 3. Creating Training and Validation Splits
To monitor model performance during training, we split the training data further using train_test_split:

python
Copy
Edit
X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)
This gives us 90% training and 10% validation data.

ðŸ”š Conclusion
Properly splitting the MNIST dataset into training, validation, and test sets ensures the model is trained well, validated during training, and tested fairly on unseen data. This is a crucial step in any machine learning pipeline.

